{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (192, 192)  # Reduced image size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 80\n",
    "\n",
    "# Data augmentation settings\n",
    "augmentation_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    \n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    fd, hog_image = hog(gray, orientations=8, pixels_per_cell=(16, 16),\n",
    "                        cells_per_block=(1, 1), visualize=True)\n",
    "    \n",
    "    hog_image = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    hog_image = np.expand_dims(hog_image, axis=-1)\n",
    "    combined_img = np.concatenate((img, hog_image), axis=-1).astype(np.float32)\n",
    "    return combined_img\n",
    "\n",
    "# Function to artificially increase the dataset size using augmentation\n",
    "def augment_and_expand_dataset(X, y):\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        img = X[i]\n",
    "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Generate augmented images\n",
    "        augment_iter = augmentation_datagen.flow(img, batch_size=1)\n",
    "        for _ in range(2):  # Reduced to 2 augmentations per image\n",
    "            aug_img = next(augment_iter)[0].astype(np.float32)\n",
    "            X_augmented.append(aug_img)\n",
    "            y_augmented.append(y[i])  # Duplicate the corresponding label\n",
    "    \n",
    "    # Add original images back into the augmented dataset\n",
    "    X_augmented.extend(X)\n",
    "    y_augmented.extend(y)\n",
    "    \n",
    "    return np.array(X_augmented, dtype=np.float32), np.array(y_augmented)\n",
    "\n",
    "def batch_process(csv_file, image_folder, batch_size=500):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    X_all = []\n",
    "    y_all = []\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for _, row in batch_df.iterrows():\n",
    "            img_path = os.path.join(image_folder, row['filename'])\n",
    "            img_array = preprocess_image(img_path)\n",
    "            X_batch.append(img_array)\n",
    "            y_batch.append(row['percentage'])\n",
    "        \n",
    "        X_batch, y_batch = augment_and_expand_dataset(np.array(X_batch), np.array(y_batch))\n",
    "        X_all.extend(X_batch)\n",
    "        y_all.extend(y_batch)\n",
    "    \n",
    "    return np.array(X_all, dtype=np.float32), np.array(y_all)\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 4))\n",
    "    \n",
    "    # Use only the RGB channels for the MobileNetV2 base\n",
    "    rgb_tensor = input_tensor[:, :, :, :3]\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "    x = base_model(rgb_tensor)\n",
    "    \n",
    "    # Fine-tune the top layers\n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Add a convolutional layer for the HOG feature\n",
    "    hog_tensor = input_tensor[:, :, :, 3:4]\n",
    "    hog_conv = Conv2D(32, (3, 3), activation='relu')(hog_tensor)\n",
    "    hog_pool = GlobalAveragePooling2D()(hog_conv)\n",
    "    \n",
    "    # Concatenate MobileNetV2 features and HOG features\n",
    "    x = Concatenate()([x, hog_pool])\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    model = create_model()\n",
    "    \n",
    "    # Data augmentation during training\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    # Ensure the generator repeats to prevent dataset exhaustion\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=BATCH_SIZE).repeat(),\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "def predict_completion(model, image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    return prediction\n",
    "\n",
    "def detect_defects(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Contour detection\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Analyze contours for potential defects\n",
    "    defects = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 100:  # Adjust this threshold as needed\n",
    "            defects.append(contour)\n",
    "    \n",
    "    return len(defects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.25 GiB for an array with shape (2283, 192, 192, 4) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCoding\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFiles\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mConstruction 2.0\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata processing (image)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load and prepare the dataset in batches\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Split dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 90\u001b[0m, in \u001b[0;36mbatch_process\u001b[1;34m(csv_file, image_folder, batch_size)\u001b[0m\n\u001b[0;32m     87\u001b[0m     X_all\u001b[38;5;241m.\u001b[39mextend(X_batch)\n\u001b[0;32m     88\u001b[0m     y_all\u001b[38;5;241m.\u001b[39mextend(y_batch)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(y_all)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.25 GiB for an array with shape (2283, 192, 192, 4) and data type float32"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = r'D:\\Coding\\Files\\Project\\Construction 2.0\\data processing (image)\\labels.csv'\n",
    "    image_folder = r'D:\\Coding\\Files\\Project\\Construction 2.0\\data processing (image)'\n",
    "\n",
    "    # Load and prepare the dataset in batches\n",
    "    X, y = batch_process(csv_file, image_folder)\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model, history = train_model(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Mean Absolute Error: {test_mae:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    model.save('construction_progress_model.h5')\n",
    "    print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('building_completion_model_0.3_augmented.h5')\n",
    "\n",
    "print(\"Enhanced model with augmented data has been trained and saved as 'building_completion_model_0.3_augmented.h5'\")\n",
    "\n",
    "# Example usage of defect detection\n",
    "sample_image_path = os.path.join(image_folder, X_test[0])\n",
    "defect_count = detect_defects(sample_image_path)\n",
    "print(f\"Number of potential defects detected: {defect_count}\")\n",
    "\n",
    "# Predict completion percentage\n",
    "completion_percentage = predict_completion(model, sample_image_path)\n",
    "print(f\"Predicted completion percentage: {completion_percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
